import transformers
import torch
import json
import random
import argparse
import pandas as pd
import os
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns
import time

from tools import *

sns.set_style("darkgrid")

def rank_products(text, product_names):
    '''
    Rank the products based on their position in the text.

    Args:
        text: The text containing the product recommendations.
        product_names: A list of product names.

    Returns:
        ranks: A dictionary containing the ranks of the products.
    '''
    # Find position of each product in the text
    position_dict = {}
    for name in product_names:
        position = text.find(name)
        if position != -1:
            position_dict[name] = position
        else:
            position_dict[name] = float('inf')

    # Sort products by position
    sorted_products = sorted(position_dict, key=position_dict.get)

    ranks = {}
    for i, prod in enumerate(sorted_products):
        if position_dict[prod] != float('inf'):
            ranks[prod] = i + 1
        else:
            ranks[prod] = len(sorted_products) + 1

    return ranks

def prompt_generator_vicuna(target_product_idx, product_list, user_msg, tokenizer, device, sts_tokens):
    '''
    Generate the prompt for the rank optimization procedure.

    Args:
        target_product_idx: The index of the target product in the product list.
        product_list: A list of products as dictionaries.
        user_msg: The user's message.
        tokenizer: The tokenizer of the model.
        device: The device to run the model.
        sts_tokens: The tokens for the strategic text sequence.

    Returns:
        sts_prompt_ids: Token IDs of the STS inserted prompt.
        sts_idxs: The indices of the STS tokens.
    '''
    
    system_prompt = "A chat between a user and an assistant. The assistant provides a numbered list of " \
                    + "product recommendations ranked based on the user's request.\n\n" \
                    + "USER:\n\nProducts:\n"

    head = system_prompt
    tail = ''

    # Generate the adversarial prompt
    for i, product in enumerate(product_list):
        if i < target_product_idx:
            head += json.dumps(product) + "\n"
        elif i == target_product_idx:
            head += json.dumps(product) + "\n"
            tail += head[-3:]
            head = head[:-3]
        else:
            tail += json.dumps(product) + "\n"

    tail += "\n" + user_msg + "\n\nASSISTANT: "

    head_tokens = tokenizer(head, return_tensors="pt")["input_ids"].to(device)
    sts_tokens = sts_tokens.to(device)
    head_sts = torch.cat((head_tokens, sts_tokens), dim=1)
    sts_idxs = torch.arange(head_sts.shape[1] - sts_tokens.shape[1], head_sts.shape[1], device=device)
    tail_tokens = tokenizer(tail, return_tensors="pt", add_special_tokens=False)["input_ids"].to(device)
    sts_prompt_ids = torch.cat((head_sts, tail_tokens), dim=1)

    return sts_prompt_ids, sts_idxs

def prompt_generator_llama(target_product_idx, product_list, user_msg, tokenizer, device, sts_tokens):
    '''
    Generate the prompt for the rank optimization procedure.

    Args:
        target_product_idx: The index of the target product in the product list.
        product_list: A list of products as dictionaries.
        user_msg: The user's message.
        tokenizer: The tokenizer of the model.
        device: The device to run the model.
        sts_tokens: The tokens for the strategic text sequence.

    Returns:
        sts_prompt_ids: Token IDs of the STS inserted prompt.
        sts_idxs: The indices of the STS tokens.
    '''
    
    system_prompt = "[INST] <<SYS>>\nA chat between a human and an artificial " \
                    + "intelligence assistant. The assistant provides a numbered list of " \
                    + "product recommendations ranked based on the user's request.\n" \
                    + "<</SYS>>\n\nProducts:\n"
    
    # system_prompt = "[INST] <<SYS>>\nA chat between a human and an artificial " \
    #                 + "intelligence assistant. The assistant provides a list of " \
    #                 + "product recommendations based on the user's request. The " \
    #                 + "assistant presents the recommendations as a numbered list " \
    #                 + "as follows: 1. product one 2. product two ...\n" \
    #                 + "<</SYS>>\n\nProducts:\n"

    head = system_prompt
    tail = ''

    # Generate the adversarial prompt
    for i, product in enumerate(product_list):
        if i < target_product_idx:
            head += json.dumps(product) + "\n"
        elif i == target_product_idx:
            head += json.dumps(product) + "\n"
            tail += head[-3:]
            head = head[:-3]
        else:
            tail += json.dumps(product) + "\n"

    tail += "\n" + user_msg + " [/INST]"

    head_tokens = tokenizer(head, return_tensors="pt")["input_ids"].to(device)
    sts_tokens = sts_tokens.to(device)
    head_sts = torch.cat((head_tokens, sts_tokens), dim=1)
    sts_idxs = torch.arange(head_sts.shape[1] - sts_tokens.shape[1], head_sts.shape[1], device=device)
    tail_tokens = tokenizer(tail, return_tensors="pt", add_special_tokens=False)["input_ids"].to(device)
    sts_prompt_ids = torch.cat((head_sts, tail_tokens), dim=1)

    return sts_prompt_ids, sts_idxs

def rank_opt(target_product_idx, product_list, model_list, tokenizer, loss_function, prompt_gen_list,
             forbidden_tokens, save_path, num_iter=1000, top_k=256, num_samples=512, batch_size=200,
             test_iter=50, num_sts_tokens=30, verbose=True, random_order=True, save_state=True):
    '''
    Implements the rank optimization procedure. The objective is to generate an optimized
    text sequence that when add to the target product in the product list will result in
    the target product being ranked as the top recommendation.

    Args:
        target_product_idx: The index of the target product in the product list.
        product_list: A list of products as dictionaries.
        model: The language model to be optimizing for.
        tokenizer: The tokenizer of the model.
        loss_function: Loss function to use. This funtion should take the embeddings of the
                       input sequence and return the loss of the target sequence (a list of loss
                       values for a batch of embeddings). Format: loss_function(embeddings, model).
        prompt_gen: A function that generates the prompt and a set of optimizable indexes for
                    the optimization procedure given the target product index, product list, tokenizer,
                    device, and adv_tokens.
        forbidden_tokens: A list of forbidden tokens.
        save_path: The path to save the plots.
        num_iter: The number of iterations for the optimization procedure.
        top_k: The number of top tokens to sample from.
        num_samples: Number of adversarial sequences to be generated in each iteration.
        batch_size: The batch size for the optimization procedure.
        test_iter: The number of iterations after which to evaluate the strategic text sequence (STS).
        num_sts_tokens: Number of tokens in the strategic text sequence.
        verbose: Whether to print progress.
        random_order: Whether to shuffle the product list in each iteration.
        save_state: Whether to save the STS and iteration number in a pytorch state dictionary.
                    This can be used to resume the experiment if it is interrupted.
    '''
    # Create directory to save plots and result
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    
    # Get product names and target product
    product_names = [product['Name'] for product in product_list]
    target_product = product_names[target_product_idx]
    num_prod = len(product_names)

    # Initialize STS tokens and other variables
    state_dict_path = save_path + "/state_dict.pth"
    if save_state and os.path.exists(state_dict_path):        
        state_dict = torch.load(state_dict_path)
        sts_tokens = state_dict["sts_tokens"]
        start_iter = state_dict["iteration"] + 1
        loss_df = state_dict["loss_df"]
        rank_df = state_dict["rank_df"]
        avg_loss = state_dict["avg_loss"]
        avg_iter_time = state_dict["avg_iter_time"]
        top_count = state_dict["top_count"]
        best_top_count = state_dict["best_top_count"]
    else:
        sts_tokens = torch.full((1, num_sts_tokens), tokenizer.encode('*')[1])  # Insert optimizable tokens
        start_iter = 0
        rank_df = pd.DataFrame(columns=["Iteration", "Rank"])
        loss_df = pd.DataFrame(columns=["Iteration", "Current Loss", "Average Loss"])
        avg_loss = 0
        avg_iter_time = 0
        # Number of times product was in top 3 recommendations
        top_count = 0
        best_top_count = 0

    decay = 0.99    # Decay factor for average loss

    input_sequence_list = []
    sts_idxs_list = []

    num_models = len(model_list)

    for i in range(num_models):
        # Generate input prompt
        inp_prompt_ids, sts_idxs = prompt_gen_list[i](target_product_idx, product_list, tokenizer, model_list[i].device, sts_tokens)
        input_sequence_list.append(inp_prompt_ids)
        sts_idxs_list.append(sts_idxs)

    if verbose:
        rand_idx = random.randint(0, num_models - 1)
        model = model_list[rand_idx]
        inp_prompt_ids = input_sequence_list[rand_idx]
        sts_idxs = sts_idxs_list[rand_idx]

        print("\nADV PROMPT:\n" + decode_adv_prompt(inp_prompt_ids[0], sts_idxs, tokenizer), flush=True)
        model_output = model.generate(inp_prompt_ids, model.generation_config, max_new_tokens=800)
        model_output_new = tokenizer.decode(model_output[0, len(inp_prompt_ids[0]):]).strip()
        print("\nLLM RESPONSE:\n" + model_output_new, flush=True)

        product_rank = rank_products(model_output_new, product_names)[target_product]
        # rank_df = pd.concat([rank_df, pd.DataFrame({"Iteration": [0], "Rank": [product_rank]})], ignore_index=True)
        if start_iter == 0:
            rank_df.loc[0] = [0, product_rank]
        print(colored(f"\nTarget Product Rank: {product_rank}", "blue"), flush=True)

        # print(f"GPU memory used: {torch.cuda.memory_allocated() / 1024 ** 3:.2f} / {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB")

        print("")
        print("\nIteration, Curr loss, Avg loss, Avg time, Opt sequence")

    for iter in range(start_iter, num_iter):

        # Perform one step of the optimization procedure
        start_time = time.time()
        # inp_prompt_ids, curr_loss = gcg_step(inp_prompt_ids, sts_idxs, model, loss_function, forbidden_tokens, top_k, num_samples, batch_size)
        input_sequence_list, curr_loss = gcg_step_multi(input_sequence_list, sts_idxs_list, model_list, loss_function, forbidden_tokens, top_k, num_samples, batch_size)
        end_time = time.time()
        iter_time = end_time - start_time
        avg_iter_time = ((iter * avg_iter_time) + iter_time) / (iter + 1)

        # Average loss with decay
        avg_loss = (((1 - decay) * curr_loss) + ((1 - (decay ** iter)) * decay * avg_loss)) / (1 - (decay ** (iter + 1)))
        
        # if iter == 0:
        #     loss_df = pd.DataFrame({"Iteration": [iter + 1], "Current Loss": [curr_loss], "Average Loss": [avg_loss]})
        # else:
        loss_df.loc[iter] = [iter + 1, curr_loss, avg_loss]

        sts_tokens = input_sequence_list[0][0, sts_idxs_list[0]].unsqueeze(0)

        if random_order:
            random.shuffle(product_list)

        # Find target product index in the shuffled list
        target_product_idx = [product['Name'] for product in product_list].index(target_product)

        input_sequence_list = []
        sts_idxs_list = []

        for i in range(num_models):
            # Generate input prompt
            inp_prompt_ids, sts_idxs = prompt_gen_list[i](target_product_idx, product_list, tokenizer, model_list[i].device, sts_tokens)
            input_sequence_list.append(inp_prompt_ids)
            sts_idxs_list.append(sts_idxs)
        
        eval_sequence_list = input_sequence_list
        eval_sts_idxs_list = sts_idxs_list

        # else:
        #     # Pick the prompt with the lowest loss
        #     if iter == 0:
        #         best_loss = curr_loss
        #         eval_sequence_list = input_sequence_list
        #         eval_sts_idxs_list = sts_idxs_list

        #     else:
        #         if curr_loss < best_loss:
        #             best_loss = curr_loss
        #             eval_sequence_list = input_sequence_list
        #             eval_sts_idxs_list = sts_idxs_list

        if verbose:
            # Print current loss and best loss
            rand_idx = random.randint(0, num_models - 1)
            model = model_list[rand_idx]
            eval_prompt_ids = eval_sequence_list[rand_idx]
            eval_opt_idxs = eval_sts_idxs_list[rand_idx]

            print(str(iter + 1) + "/{}, {:.4f}, {:.4f}, {:.1f}s, {}".format(num_iter, curr_loss, avg_loss, avg_iter_time, colored(tokenizer.decode(eval_prompt_ids[0, eval_opt_idxs]), 'red'))
                                                           + " " * 10, flush=True, end="\r")

            # Evaluate STS every test_iter iterations
            if (iter + 1) % test_iter == 0 or iter == num_iter - 1:
                
                print("\n\nEvaluating STS...")
                print("\nADV PROMPT:\n" + decode_adv_prompt(eval_prompt_ids[0], eval_opt_idxs, tokenizer), flush=True)
                model_output = model.generate(eval_prompt_ids, model.generation_config, max_new_tokens=800)
                model_output_new = tokenizer.decode(model_output[0, len(eval_prompt_ids[0]):]).strip()
                print("\nLLM RESPONSE:\n" + model_output_new, flush=True)

                product_rank = rank_products(model_output_new, product_names)[target_product]
                # rank_df = pd.concat([rank_df, pd.DataFrame({"Iteration": [iter + 1], "Rank": [product_rank]})], ignore_index=True)
                rank_df.loc[len(rank_df)] = [iter + 1, product_rank]
                print(colored(f"\nTarget Product Rank: {product_rank}", "blue"), flush=True)
                rank_df.to_csv(save_path + "/rank.csv", index=False)

                # Update top count
                if product_rank <= 3:
                    top_count += 1
                else:
                    top_count = 0

                # Save product line with optimized sequence
                if top_count >= best_top_count:
                    best_top_count = top_count
                    eval_prompt_str = tokenizer.decode(eval_prompt_ids[0])
                    eval_prompt_lines = eval_prompt_str.split("\n")
                    for _, line in enumerate(eval_prompt_lines):
                        if target_product in line:
                            with open(save_path + "/sts.txt", "w") as file:
                                file.write(line + "\n")
                            break

                # print(f"GPU memory used: {torch.cuda.memory_allocated() / 1024 ** 3:.2f} / {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB")
                print(f'\nTop count: {top_count}, Best top count: {best_top_count}', flush=True)

                # Plot iteration vs. top as dots
                plt.figure(figsize=(7, 4))
                sns.scatterplot(data=rank_df, x="Iteration", y="Rank", s=80)
                plt.fill_between([-(0.015*num_iter), num_iter + (0.015*num_iter)], (num_prod+1) * 1.04, num_prod + 0.5, color="grey", alpha=0.3, zorder=0)
                plt.xlabel("Iteration", fontsize=16)
                plt.ylabel("Rank", fontsize=16)
                plt.ylim((num_prod+1) * 1.04, 1 - ((num_prod+1) * 0.04))
                plt.yticks(range(num_prod, 0, -1), fontsize=14)
                plt.title("Target Product Rank", fontsize=18)
                plt.xlim(-(0.015*num_iter), num_iter + (0.015*num_iter))
                plt.xticks(range(0, num_iter + 1, num_iter//5), fontsize=14)
                grey_patch = mpatches.Patch(color='grey', alpha=0.3, label='Not Recommended')
                plt.legend(handles=[grey_patch])
                plt.tight_layout() # Adjust the plot to the figure
                plt.savefig(save_path + "/rank.png")
                plt.close()

                # Plot iteration vs. current loss and average loss
                plt.figure(figsize=(7, 4))
                sns.lineplot(data=loss_df, x="Iteration", y="Current Loss", label="Current Loss")
                sns.lineplot(data=loss_df, x="Iteration", y="Average Loss", label="Average Loss", linewidth=2)
                plt.xlabel("Iteration", fontsize=16)
                plt.xticks(fontsize=14)
                plt.ylabel("Loss", fontsize=16)
                plt.yticks(fontsize=14)
                plt.title("Current and Average Loss", fontsize=18)
                plt.tight_layout() # Adjust the plot to the figure
                plt.savefig(save_path + "/loss.png")
                plt.close()

                if iter < num_iter - 1:                    
                    print("")
                    print("Iteration, Curr loss, Avg loss, Opt sequence", flush=True)

        if save_state:
            # Save the STS and iteration number in a pytorch state dictionary
            state_dict = {
                "iteration": iter,
                "sts_tokens": sts_tokens,
                "loss_df": loss_df,
                "rank_df": rank_df,
                "avg_loss": avg_loss,
                "avg_iter_time": avg_iter_time,
                "top_count": top_count,
                "best_top_count": best_top_count
            }
            torch.save(state_dict, state_dict_path)

    print("")


if __name__ == "__main__":

    argparser = argparse.ArgumentParser(description="Product Rank Optimization")
    argparser.add_argument("--results_dir", type=str, default="results/test", help="The directory to save the results.")
    argparser.add_argument("--catalog", type=str, default="coffee_machines", choices=["election_articles","coffee_machines", "books", "cameras"], help="The product catalog to use.")
    argparser.add_argument("--num_iter", type=int, default=500, help="The number of iterations.")
    argparser.add_argument("--test_iter", type=int, default=20, help="The number of test iterations.")
    argparser.add_argument("--random_order", action="store_true", help="Whether to shuffle the product list in each iteration.")
    argparser.add_argument("--target_product_idx", type=int, default=0, help="The index of the target product in the product list.")
    argparser.add_argument("--mode", type=str, default="self", choices=["self", "transfer"], help="Mode of optimization.")
    argparser.add_argument("--user_msg_type", type=str, default="default", choices=["default", "custom"], help="User message type.")
    argparser.add_argument("--save_state", action="store_true", help="Whether to save the state of the optimization procedure. If interrupted, the experiment can be resumed.")
    args = argparser.parse_args()

    results_dir = args.results_dir
    user_msg_type = args.user_msg_type
    if args.catalog == "coffee_machines":
        catalog = "data/coffee_machines.jsonl"
        if user_msg_type == "default":
            user_msg = "I am looking for a coffee machine. Can I get some recommendations?"
        elif user_msg_type == "custom":
            user_msg = "I am looking for an affordable coffee machine. Can I get some recommendations?"
    elif args.catalog == "books":
        catalog = "data/books.jsonl"
        if user_msg_type == "default":
            user_msg = "I am looking for a book in any genre. Can I get some recommendations?"
            # user_msg = "I am looking for a book. Can I get some recommendations?"
        elif user_msg_type == "custom":
            user_msg = "I am looking for a good adventure novel. Can I get some recommendations?"
    elif args.catalog == "cameras":
        catalog = "data/cameras.jsonl"
        if user_msg_type == "default":
            user_msg = "I am looking for a camera. Can I get some recommendations?"
        elif user_msg_type == "custom":
            user_msg = "I am looking for a high resolution camera. Can I get some recommendations?"
    elif args.catalog == "election_articles":
        catalog = "data/election_articles.jsonl"
        if user_msg_type == "default":
            user_msg = "I am looking for an article. Can I get some recommendations?"
    else:
        raise ValueError("Invalid catalog.")
    num_iter = args.num_iter
    test_iter = args.test_iter
    random_order = args.random_order
    mode = args.mode
    save_state = args.save_state
    # Use models with similar tokenizers
    model_path_llama_7b = "meta-llama/Llama-2-7b-chat-hf"

    if mode == "transfer":
        model_path_vicuna_7b = "lmsys/vicuna-7b-v1.5"
    
    batch_size = 150

    # Set device
    # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Get list of all cuda device names
    cuda_devices = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]

    print("\n* * * * * Experiment Parameters * * * * *")
    print(f"Device(s): {cuda_devices}")
    print("Mode:", mode)
    if mode == "self":
        print("Model path:", model_path_llama_7b)
    else:
        print("Model 1 path:", model_path_llama_7b)
        print("Model 2 path:", model_path_vicuna_7b)
    print("Product catalog:", catalog)
    print(f"User message type: {user_msg_type}")
    print("Number of iterations:", num_iter)
    print("Test iteration interval:", test_iter)
    print("Batch size:", batch_size)
    print("Shuffle product list:", random_order)
    print("Results directory:", results_dir)
    print("Save state:", save_state)
    print("* * * * * * * * * * * * * * * * * * * * *\n")

    # Load model and tokenizer
    model_llama_7b = transformers.AutoModelForCausalLM.from_pretrained(
        model_path_llama_7b,
        torch_dtype=torch.float16,
        trust_remote_code=True,
        low_cpu_mem_usage=True,
        use_cache=False,
        )
    
    # Put model in eval mode and turn off gradients of model parameters
    # model_llama_7b.to(device).eval()
    model_llama_7b.to(torch.device("cuda:0")).eval()
    for param in model_llama_7b.parameters():
        param.requires_grad = False
        
    if mode == "transfer":
        model_vicuna_7b = transformers.AutoModelForCausalLM.from_pretrained(
            model_path_vicuna_7b,
            torch_dtype=torch.float16,
            trust_remote_code=True,
            low_cpu_mem_usage=True,
            use_cache=False,
            )
        
        # Put model in eval mode and turn off gradients of model parameters
        # model_vicuna_7b.to(device).eval()
        model_vicuna_7b.to(torch.device("cuda:1")).eval()
        for param in model_vicuna_7b.parameters():
            param.requires_grad = False

    tokenizer_llama = transformers.AutoTokenizer.from_pretrained(model_path_llama_7b)

    # Load products from JSONL file
    product_list = []
    with open(catalog, "r") as file:
        for line in file:
            product_list.append(json.loads(line))

    if args.target_product_idx <= 0:
        target_product_idx = random.randint(0, len(product_list) - 1)
    else:
        target_product_idx = args.target_product_idx - 1

    product_names = [product['Name'] for product in product_list]

    target_product = product_list[target_product_idx]['Name']

    target_str = "1. " + target_product
    print("\nTARGET STR:", target_str)

    # Get forbidden tokens
    forbidden_tokens = get_nonascii_toks(tokenizer_llama)

    # Lambda function for the target loss and prompt generator
    loss_fn = lambda embeddings, model: target_loss(embeddings, model, tokenizer_llama, target_str)
    prompt_gen_llama = lambda adv_target_idx, prod_list, tokenizer, device, adv_tokens: prompt_generator_llama(adv_target_idx, prod_list, user_msg, tokenizer, device, adv_tokens)

    if mode == "transfer":
        prompt_gen_vicuna = lambda adv_target_idx, prod_list, tokenizer, device, adv_tokens: prompt_generator_vicuna(adv_target_idx, prod_list, user_msg, tokenizer, device, adv_tokens)

    if mode == "self":
        rank_opt(target_product_idx, product_list, [model_llama_7b], tokenizer_llama, loss_fn, [prompt_gen_llama],
                forbidden_tokens, results_dir, test_iter=test_iter, batch_size=batch_size, num_iter=num_iter, random_order=random_order, save_state=save_state)
    else:
        rank_opt(target_product_idx, product_list, [model_llama_7b, model_vicuna_7b], tokenizer_llama, loss_fn, [prompt_gen_llama, prompt_gen_vicuna],
                forbidden_tokens, results_dir, test_iter=test_iter, batch_size=batch_size, num_iter=num_iter, random_order=random_order, save_state=save_state)